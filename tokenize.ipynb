{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yyoo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to run only ONCE\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Before we proceed any further, hear me speak.\\nSpeak, speak.\\nYou are all resolved rather to die than to famish?\\nResolved. resolved.\\nFirst, you know Caius Marcius is chief enemy to the people.\\nWe know't, we know't.\\nLet us kill him, and we'll have corn at our own price.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/text.txt', 'r') as fp:\n",
    "    texts = fp.read()\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenize by sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Before we proceed any further, hear me speak.',\n",
       " 'Speak, speak.',\n",
       " 'You are all resolved rather to die than to famish?',\n",
       " 'Resolved.',\n",
       " 'resolved.',\n",
       " 'First, you know Caius Marcius is chief enemy to the people.',\n",
       " \"We know't, we know't.\",\n",
       " \"Let us kill him, and we'll have corn at our own price.\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "sentences = sent_tokenize(texts)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenize by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Before',\n",
       " 'we',\n",
       " 'proceed',\n",
       " 'any',\n",
       " 'further',\n",
       " ',',\n",
       " 'hear',\n",
       " 'me',\n",
       " 'speak',\n",
       " '.',\n",
       " 'Speak',\n",
       " ',',\n",
       " 'speak',\n",
       " '.',\n",
       " 'You',\n",
       " 'are',\n",
       " 'all',\n",
       " 'resolved',\n",
       " 'rather',\n",
       " 'to',\n",
       " 'die',\n",
       " 'than',\n",
       " 'to',\n",
       " 'famish',\n",
       " '?',\n",
       " 'Resolved',\n",
       " '.',\n",
       " 'resolved',\n",
       " '.',\n",
       " 'First',\n",
       " ',',\n",
       " 'you',\n",
       " 'know',\n",
       " 'Caius',\n",
       " 'Marcius',\n",
       " 'is',\n",
       " 'chief',\n",
       " 'enemy',\n",
       " 'to',\n",
       " 'the',\n",
       " 'people',\n",
       " '.',\n",
       " 'We',\n",
       " \"know't\",\n",
       " ',',\n",
       " 'we',\n",
       " \"know't\",\n",
       " '.',\n",
       " 'Let',\n",
       " 'us',\n",
       " 'kill',\n",
       " 'him',\n",
       " ',',\n",
       " 'and',\n",
       " 'we',\n",
       " \"'ll\",\n",
       " 'have',\n",
       " 'corn',\n",
       " 'at',\n",
       " 'our',\n",
       " 'own',\n",
       " 'price',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "words = word_tokenize(texts)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## token 의 빈도분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Before': 1,\n",
       " 'we': 3,\n",
       " 'proceed': 1,\n",
       " 'any': 1,\n",
       " 'further': 1,\n",
       " ',': 5,\n",
       " 'hear': 1,\n",
       " 'me': 1,\n",
       " 'speak': 2,\n",
       " '.': 7,\n",
       " 'Speak': 1,\n",
       " 'You': 1,\n",
       " 'are': 1,\n",
       " 'all': 1,\n",
       " 'resolved': 2,\n",
       " 'rather': 1,\n",
       " 'to': 3,\n",
       " 'die': 1,\n",
       " 'than': 1,\n",
       " 'famish': 1,\n",
       " '?': 1,\n",
       " 'Resolved': 1,\n",
       " 'First': 1,\n",
       " 'you': 1,\n",
       " 'know': 1,\n",
       " 'Caius': 1,\n",
       " 'Marcius': 1,\n",
       " 'is': 1,\n",
       " 'chief': 1,\n",
       " 'enemy': 1,\n",
       " 'the': 1,\n",
       " 'people': 1,\n",
       " 'We': 1,\n",
       " \"know't\": 2,\n",
       " 'Let': 1,\n",
       " 'us': 1,\n",
       " 'kill': 1,\n",
       " 'him': 1,\n",
       " 'and': 1,\n",
       " \"'ll\": 1,\n",
       " 'have': 1,\n",
       " 'corn': 1,\n",
       " 'at': 1,\n",
       " 'our': 1,\n",
       " 'own': 1,\n",
       " 'price': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "token_dict = dict(FreqDist(words))\n",
    "token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".           7\n",
       ",           5\n",
       "we          3\n",
       "to          3\n",
       "speak       2\n",
       "know't      2\n",
       "resolved    2\n",
       "Before      1\n",
       "us          1\n",
       "chief       1\n",
       "enemy       1\n",
       "the         1\n",
       "people      1\n",
       "We          1\n",
       "Let         1\n",
       "kill        1\n",
       "Marcius     1\n",
       "him         1\n",
       "and         1\n",
       "'ll         1\n",
       "have        1\n",
       "corn        1\n",
       "at          1\n",
       "our         1\n",
       "own         1\n",
       "is          1\n",
       "you         1\n",
       "Caius       1\n",
       "are         1\n",
       "proceed     1\n",
       "any         1\n",
       "further     1\n",
       "hear        1\n",
       "me          1\n",
       "Speak       1\n",
       "You         1\n",
       "all         1\n",
       "know        1\n",
       "rather      1\n",
       "die         1\n",
       "than        1\n",
       "famish      1\n",
       "?           1\n",
       "Resolved    1\n",
       "First       1\n",
       "price       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "texts_token_series = pd.Series(token_dict)\n",
    "texts_token_series.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Before', 'we', 'proceed', 'any', 'further', ',', 'hear', 'me', 'speak', '.', 'Speak', ',', 'speak', '.', 'You', 'are', 'all', 'resolved', 'rather', 'to', 'die', 'than', 'to', 'famish', '?', 'Resolved', '.', 'resolved', '.', 'First', ',', 'you', 'know', 'Caius', 'Marcius', 'is', 'chief', 'enemy', 'to', 'the', 'people', '.', 'We', 'know', \"'\", 't', ',', 'we', 'know', \"'\", 't', '.', 'Let', 'us', 'kill', 'him', ',', 'and', 'we', \"'\", 'll', 'have', 'corn', 'at', 'our', 'own', 'price', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "token = tokenizer.tokenize(texts)\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Before', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('proceed', 'VBP'),\n",
       " ('any', 'DT'),\n",
       " ('further', 'JJ'),\n",
       " (',', ','),\n",
       " ('hear', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('speak', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Speak', 'NNP'),\n",
       " (',', ','),\n",
       " ('speak', 'NN'),\n",
       " ('.', '.'),\n",
       " ('You', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('all', 'DT'),\n",
       " ('resolved', 'VBD'),\n",
       " ('rather', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('die', 'VB'),\n",
       " ('than', 'IN'),\n",
       " ('to', 'TO'),\n",
       " ('famish', 'VB'),\n",
       " ('?', '.'),\n",
       " ('Resolved', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('resolved', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('First', 'NNP'),\n",
       " (',', ','),\n",
       " ('you', 'PRP'),\n",
       " ('know', 'VBP'),\n",
       " ('Caius', 'NNP'),\n",
       " ('Marcius', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('chief', 'JJ'),\n",
       " ('enemy', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('people', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('know', 'VBP'),\n",
       " (\"'\", \"''\"),\n",
       " ('t', 'JJ'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('know', 'VBP'),\n",
       " (\"'\", \"''\"),\n",
       " ('t', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Let', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('kill', 'VB'),\n",
       " ('him', 'PRP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " (\"'\", \"''\"),\n",
       " ('ll', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('corn', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('own', 'JJ'),\n",
       " ('price', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "pos_tag(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tag 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to /Users/yyoo/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n"
     ]
    }
   ],
   "source": [
    "import nltk.help as nltk_help\n",
    "nltk_help.upenn_tagset('PRP')  # 대명사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n"
     ]
    }
   ],
   "source": [
    "nltk_help.upenn_tagset('JJ')  # 형용사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/yyoo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'him', 'which', 'had', 'at', 'in', 'both', 's', 'aren', \"mightn't\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')[::18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "punct = string.punctuation\n",
    "punct = [punct[i] for i in range(len(punct))]\n",
    "\n",
    "words_to_remove = punct + stopwords.words('english') + ['\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Before', 'proceed', 'hear', 'speak', 'Speak', 'speak', 'You', 'resolved', 'rather', 'die', 'famish', 'Resolved', 'resolved', 'First', 'know', 'Caius', 'Marcius', 'chief', 'enemy', 'people', 'We', 'know', 'know', 'Let', 'us', 'kill', 'corn', 'price']\n"
     ]
    }
   ],
   "source": [
    "token = [word for word in token  \n",
    "         if word not in words_to_remove]\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
